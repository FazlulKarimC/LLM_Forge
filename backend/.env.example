# LLM Research Platform - Environment Configuration
# Copy this to .env and fill in your values

# =============================================================================
# APPLICATION
# =============================================================================
PROJECT_NAME="LLM Research Platform"
VERSION="0.1.0"
ENVIRONMENT=development
DEBUG=true
API_V1_PREFIX=/api/v1

# =============================================================================
# DATABASE (NeonDB)
# =============================================================================
# Get your connection string from: https://console.neon.tech
DATABASE_URL=postgresql://user:password@host.neon.tech/dbname?sslmode=require

# =============================================================================
# VECTOR DATABASE (Qdrant)
# =============================================================================
# Local: http://localhost:6333
# Cloud: https://your-cluster.qdrant.io
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=documents

# =============================================================================
# HUGGING FACE
# =============================================================================
# Get your token from: https://huggingface.co/settings/tokens
HF_TOKEN=
HF_CACHE_DIR=./models

# =============================================================================
# INFERENCE
# =============================================================================
# Inference engine: "mock" for development, "hf_api" for real API
INFERENCE_ENGINE=mock
DEFAULT_MODEL=microsoft/phi-2
DEFAULT_MAX_TOKENS=256
DEFAULT_TEMPERATURE=0.7
INFERENCE_BATCH_SIZE=1
INFERENCE_TIMEOUT_SECONDS=60

# =============================================================================
# CORS (comma-separated origins)
# =============================================================================
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
